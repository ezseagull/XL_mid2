{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffef3b17",
   "metadata": {},
   "source": [
    "# 1. Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e41d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e083474",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02563ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_rects_detection(gray_img, scaleFactor=1.1, minNeighbors=5):\n",
    "    faces = face_classifier.detectMultiScale(\n",
    "    gray_img, scaleFactor, minNeighbors, minSize=(40, 40)\n",
    "    )\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca9033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(cv2_img, figsize=(20,10), axis=\"off\", cmap=None):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    if cmap is None:\n",
    "        plt.imshow(cv2_img)\n",
    "    else:\n",
    "        plt.imshow(cv2_img, cmap)\n",
    "    plt.axis(axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1beecd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rects(img, rects, color=(0, 255, 0), width=4):\n",
    "    img_cpy = img.copy()\n",
    "    for (x, y, w, h) in rects:\n",
    "        cv2.rectangle(img_cpy, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
    "    return img_cpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5f8a04",
   "metadata": {},
   "source": [
    "# 2. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d79fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import feature\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8aae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIRECTORY = \"./images/celeb-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "28760ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collections(directory=IMAGE_DIRECTORY):\n",
    "    collections = {}\n",
    "    for root, dirs, files in os.walk(directory, topdown=False):\n",
    "        for name in files:\n",
    "            file_path = os.path.join(root, name)\n",
    "            dir_path = os.path.dirname(file_path)\n",
    "            dir_name = os.path.basename(dir_path)\n",
    "            if not dir_name in collections:\n",
    "                collections[dir_name] = []\n",
    "            collections[dir_name].append(file_path)\n",
    "    return collections\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "30659cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_one_gray_face(file_path, reshape=None):\n",
    "    img = cv2.imread(file_path)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    rects = face_rects_detection(gray_img)\n",
    "    if len(rects) > 0:\n",
    "        rect = rects[0]\n",
    "        x, y, w, h = rect\n",
    "        crop_image = gray_img[y: y + h, x : x + w]\n",
    "        if reshape is not None:\n",
    "            crop_image = cv2.resize(crop_image, reshape)\n",
    "        return crop_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "346151ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gray_collections(dir_collections, reshape=None):\n",
    "    gray_collections = {}\n",
    "    for key, files in dir_collections.items():\n",
    "        if key not in gray_collections:\n",
    "            gray_collections[key] = []\n",
    "        for file in files:\n",
    "            face_img = exact_one_gray_face(file, reshape)\n",
    "            if face_img is not None:\n",
    "                gray_collections[key].append(face_img)\n",
    "    return gray_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f2a90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBinaryPatterns:\n",
    "\tdef __init__(self, numPoints, radius):\n",
    "\t\t# store the number of points and radius\n",
    "\t\tself.numPoints = numPoints\n",
    "\t\tself.radius = radius\n",
    "\n",
    "\tdef describe(self, image, eps=1e-7):\n",
    "\t\t# compute the Local Binary Pattern representation\n",
    "\t\t# of the image, and then use the LBP representation\n",
    "\t\t# to build the histogram of patterns\n",
    "\t\tlbp = feature.local_binary_pattern(image, self.numPoints,\n",
    "\t\t\tself.radius, method=\"uniform\")\n",
    "\t\t(hist, _) = np.histogram(lbp.ravel(),\n",
    "\t\t\tbins=np.arange(0, self.numPoints + 3),\n",
    "\t\t\trange=(0, self.numPoints + 2))\n",
    "\n",
    "\t\t# normalize the histogram\n",
    "\t\thist = hist.astype(\"float\")\n",
    "\t\thist /= (hist.sum() + eps)\n",
    "\n",
    "\t\t# return the histogram of Local Binary Patterns\n",
    "\t\treturn lbp, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c09b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image(img, gridW=7, gridH=7):\n",
    "    img_resized = cv2.resize(img, (img.shape[1] // gridW * gridW, img.shape[0] // gridH * gridH))\n",
    "    grid_list = []\n",
    "    stepW = img.shape[1] // gridW\n",
    "    stepH = img.shape[0] // gridH\n",
    "    for i in range(0, img_resized.shape[0], stepH):\n",
    "        for j in range(0, img_resized.shape[1], stepH):\n",
    "            grid_list.append(img_resized[i:i+stepH, j:j+stepW])\n",
    "    return grid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0b14d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = LocalBinaryPatterns(8 , 2)\n",
    "def get_vector_feature(grid_list, pattern=desc):\n",
    "    hists = []\n",
    "    for grid in grid_list:\n",
    "        lbp , hist = desc.describe(grid)\n",
    "        hists.append(hist)\n",
    "    concat = np.concatenate(hists)\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7955be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = get_collections()\n",
    "gray_collections = get_gray_collections(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b50dc683",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_list = split_image(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5ce0e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = get_vector_feature(grid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fb6019f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.his()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92205af",
   "metadata": {},
   "source": [
    "# Random Forest with Gray Face Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "34db629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b97ee023",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = get_collections(\"./images/collections\")\n",
    "gray_collections = get_gray_collections(collections, reshape=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1bfdec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "label2Id = {}\n",
    "id2Label = {}\n",
    "for idx, label in enumerate(gray_collections.keys()):\n",
    "    label2Id[label] = idx\n",
    "    id2Label[idx] = label\n",
    "for label, gray_imgs in gray_collections.items():\n",
    "    for gray_img in gray_imgs:\n",
    "        X.append(gray_img.flatten())\n",
    "        y.append(label2Id[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "49a2fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).astype(np.float32)\n",
    "y = np.array(y).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1f637ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X /= 255\n",
    "n_samples, n_features = X.shape\n",
    "X -= X.mean(axis=0)\n",
    "X -= X.mean(axis=1).reshape(n_samples, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "548a0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=21, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "856a6e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410 137\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a6b8899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtree = cv2.ml.RTrees_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "bab67a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = 50\n",
    "eps = 0.01\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS,\n",
    "            num_trees, eps)\n",
    "rtree.setTermCriteria(criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f53cf64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtree.setMaxCategories(len(np.unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8aefe102",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtree.setMinSampleCount(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "bae077cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtree.setMaxDepth(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "7c60dc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = cv2.ml.TrainData_create(X_train, cv2.ml.ROW_SAMPLE, y_train)\n",
    "rtree.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "47dcf416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtree.getMaxDepth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "041069e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y_hat = rtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8378a866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6277372262773723"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4e4a85d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32116788321167883"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=21, max_depth=25)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "48f5863a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.708029197080292"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_trees = 100\n",
    "eps = 0.01\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS,\n",
    "            num_trees, eps)\n",
    "rtree.setTermCriteria(criteria)\n",
    "rtree.train(X_train, cv2.ml.ROW_SAMPLE, y_train);\n",
    "_, y_hat = rtree.predict(X_test)\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca2b315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3763777c",
   "metadata": {},
   "source": [
    "# LBPH + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "573c0c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f2620b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lbp(gray):\n",
    "    row       = gray.shape[0]\n",
    "    col       = gray.shape[1]\n",
    "    neighbors = 8\n",
    "    radius    = 2\n",
    "    weight    = [[1,1,1,1,1,1,1],\n",
    "                 [1,1,1,1,1,1,1],\n",
    "                 [1,1,1,1,1,1,1],\n",
    "                 [0,1,1,1,1,1,0],\n",
    "                 [0,1,1,1,1,1,0],\n",
    "                 [0,1,1,1,1,1,0],\n",
    "                 [0,1,1,1,1,1,0]]\n",
    "\n",
    "    #extract the LBP feature of the whole image\n",
    "    lbp = local_binary_pattern(gray, \n",
    "                             neighbors,\n",
    "                             radius, \n",
    "                             method=\"uniform\")\n",
    "    local_hist=[]\n",
    "    for r in range(7):\n",
    "        for c in range(7):\n",
    "            \n",
    "            #the range of the block\n",
    "            r_start = r * int(row / 7)\n",
    "            c_start = c * int(col / 7)\n",
    "            \n",
    "            if((r + 1) * int(row / 7) <= row):\n",
    "                r_end = (r + 1) * int(row / 7)\n",
    "            else:\n",
    "                r_end = row\n",
    "            if((c + 1) * int(col / 7) <= col):\n",
    "                c_end = (c + 1) * int(col / 7)\n",
    "            else:\n",
    "                c_end = col\n",
    "            if not weight[r][c] == 0:\n",
    "                #get the regional histogram\n",
    "                (hist_temp, _) = np.histogram(lbp[r_start:r_end, c_start:c_end].ravel(),\n",
    "                                              bins=np.arange(0, neighbors + 3),\n",
    "                                              range=(0, neighbors + 2))\n",
    "                #normalize the histogram\n",
    "                hist_temp = hist_temp.astype(\"float\")\n",
    "                hist_temp /= (hist_temp.sum())\n",
    "                \n",
    "            local_hist = local_hist + list(hist_temp * weight[r][c])\n",
    "    return lbp, local_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "41d339df",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = get_collections(\"./images/collections\")\n",
    "gray_collections = get_gray_collections(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4200bdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9'])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3a0652ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "label2Id = {}\n",
    "id2Label = {}\n",
    "for idx, label in enumerate(gray_collections.keys()):\n",
    "    label2Id[label] = idx\n",
    "    id2Label[idx] = label\n",
    "    \n",
    "desc = LocalBinaryPatterns(8 , 2)\n",
    "for label, gray_imgs in gray_collections.items():\n",
    "    for gray_img in gray_imgs:\n",
    "        lbp, local_hist = get_lbp(gray_img)\n",
    "        X.append(local_hist)\n",
    "        y.append(label2Id[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ae240e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).astype(np.float32)\n",
    "y = np.array(y).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "70aeff59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(547, 490)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "17eb24c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X /= 255\n",
    "# n_samples, n_features = X.shape\n",
    "# X -= X.mean(axis=0)\n",
    "# X -= X.mean(axis=1).reshape(n_samples, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8318761a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(547, 490)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "50dd0df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=21, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "818c0a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "410"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cf7c78b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtree = cv2.ml.RTrees_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fe623ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = 50\n",
    "eps = 0.01\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS,\n",
    "            num_trees, eps)\n",
    "rtree.setTermCriteria(criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3a00c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtree.setMaxCategories(len(np.unique(y)))\n",
    "rtree.setMinSampleCount(2)\n",
    "rtree.setMaxDepth(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "43bdca0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = cv2.ml.TrainData_create(X_train, cv2.ml.ROW_SAMPLE, y_train)\n",
    "rtree.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "00bd03b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtree.getMaxDepth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c1054cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.583941605839416"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, y_hat = rtree.predict(X_test)\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "593a2105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30656934306569344"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=21, max_depth=25)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "85ee83d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6277372262773723"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_trees = 75\n",
    "eps = 0.01\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS,\n",
    "            num_trees, eps)\n",
    "rtree.setTermCriteria(criteria)\n",
    "rtree.train(X_train, cv2.ml.ROW_SAMPLE, y_train);\n",
    "_, y_hat = rtree.predict(X_test)\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c1894e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "555cdf61",
   "metadata": {},
   "source": [
    "# OpenCV LBPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a36a4195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "49fc1464",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'face'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[248], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recognizer \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface\u001b[49m\u001b[38;5;241m.\u001b[39mLBPHFaceRecognizer_create() \n\u001b[0;32m      2\u001b[0m detector  \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(\n\u001b[0;32m      3\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mhaarcascades \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaarcascade_frontalface_default.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'face'"
     ]
    }
   ],
   "source": [
    "recognizer = cv2.face.LBPHFaceRecognizer_create() \n",
    "detector  = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19523459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
